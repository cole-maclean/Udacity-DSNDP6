{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import feedparser\n",
    "def build_arxiv_cat_index():\n",
    "    url = 'http://arxiv.org/help/api/user-manual#python_simple_example'\n",
    "    data = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    cat_table = soup.findAll('tbody')[7]\n",
    "    results = {}\n",
    "    for row in cat_table.findAll('tr'):\n",
    "        aux = row.findAll('td')\n",
    "        try:\n",
    "            if aux[0].string.strip().split('.')[0] in results.keys():\n",
    "                results[aux[0].string.strip().split('.')[0]].append(aux[0].string.strip())\n",
    "            else:\n",
    "                results[aux[0].string.strip().split('.')[0]] =[aux[0].string.strip()]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "def query_arxiv(category):\n",
    "    url = 'http://export.arxiv.org/api/query?search_query=cat:' + category + '&max_results=1'\n",
    "    data = urllib.urlopen(url).read()\n",
    "    d = feedparser.parse(data)\n",
    "    max_results =  d['feed']['opensearch_totalresults']\n",
    "    query_start = 1\n",
    "    query_results = ''\n",
    "    while query_start < int(max_results):\n",
    "        url = ('http://export.arxiv.org/api/query?search_query=cat:'\n",
    "               + category + '&max_results=1000&start=' + str(query_start) + '&sortBy=submittedDate&sortOrder=ascending')\n",
    "        query_results = query_results + urllib.urlopen(url).read()\n",
    "        query_start = query_start + 1000\n",
    "    return feedparser.parse(query_results)['entries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print len(build_arxiv_cat_index().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arxiv_cat_index = build_arxiv_cat_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/27889873/clustering-text-documents-using-scikit-learn-kmeans-in-python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import difflib\n",
    "\n",
    "def paper_category_model(paper_titles):\n",
    "    true_k = 10\n",
    "    vectorizer = TfidfVectorizer(stop_words='english',min_df=0.05)\n",
    "    X = vectorizer.fit_transform(paper_titles)\n",
    "    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,random_state=42)\n",
    "    model.fit(X)\n",
    "    return (vectorizer,model)\n",
    "def get_best_parent(paper_category,sorted_categories,discipline):\n",
    "    bp = difflib.get_close_matches(paper_category,sorted_categories,1)\n",
    "    if bp:\n",
    "        return bp[0]\n",
    "    else:\n",
    "        return discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "sorted_entries = sorted(results,key= lambda k:k['published_parsed'][0])\n",
    "old_year = sorted_entries[0]['published_parsed'][0]\n",
    "data_model = {old_year:{}}\n",
    "all_paper_titles ={}\n",
    "discipline_cat_models = {} #0 - vectorizer, 1-model\n",
    "for paper in sorted_entries:\n",
    "    parsed_paper = {k:v for (k,v) in paper.iteritems() if k not in ['published_parsed','summary_detail','updated_parsed']}\n",
    "    new_year = paper['published_parsed'][0]\n",
    "    discipline = paper['arxiv_primary_category']['term'].split('.')[0]\n",
    "    paper_title = paper['title']\n",
    "    if discipline in discipline_cat_models.keys():\n",
    "        disc_vectorizer,disc_model = discipline_cat_models[discipline]\n",
    "        paper_vector = disc_vectorizer.transform([paper['title']])\n",
    "        paper_cluster = disc_model.predict(paper_vector)[0]\n",
    "        ordered_centroids = disc_model.cluster_centers_.argsort()[:, ::-1]\n",
    "        terms = disc_vectorizer.get_feature_names()\n",
    "        try:\n",
    "            paper_category = ' '.join(sorted([terms[ind] for ind in ordered_centroids[paper_cluster, :3]]))\n",
    "        except IndexError:\n",
    "            paper_category = discipline\n",
    "    else:\n",
    "        paper_category = discipline\n",
    "    if new_year != old_year:\n",
    "        data_model[new_year] = copy.deepcopy(data_model[old_year])#stores results of previous year to build cummulative model\n",
    "        old_year = new_year\n",
    "        for model_discipline in all_paper_titles.keys():\n",
    "            if len(all_paper_titles[model_discipline]) > 50:\n",
    "                discipline_cat_models[model_discipline] = paper_category_model(all_paper_titles[model_discipline])  \n",
    "    if discipline in data_model[new_year].keys():\n",
    "        sorted_categories = ([k for (k,v) in sorted(data_model[new_year][discipline]['categories'].items(),\n",
    "                                                    key=lambda (k, v): v['paper_count'],reverse=True)])\n",
    "        all_paper_titles[discipline].append(paper_title)\n",
    "        if paper_category in data_model[new_year][discipline]['categories'].keys():\n",
    "            data_model[new_year][discipline]['paper_count']+=1\n",
    "            data_model[new_year][discipline]['categories'][paper_category]['papers'].append(parsed_paper)\n",
    "            data_model[new_year][discipline]['categories'][paper_category]['paper_count'] +=1\n",
    "        else:\n",
    "            best_parent = get_best_parent(paper_category,sorted_categories,discipline)\n",
    "            data_model[new_year][discipline]['paper_count']+=1\n",
    "            data_model[new_year][discipline]['categories'][paper_category] = ({'parent_cat':best_parent,\n",
    "                                                                               'category':paper_category,\n",
    "                                                                               'papers':[parsed_paper],\n",
    "                                                                              'paper_count':1})\n",
    "    else:\n",
    "        all_paper_titles[discipline]=[paper_title]\n",
    "        best_parent = discipline\n",
    "        data_model[new_year][discipline]=({'paper_count':1,\n",
    "            'categories':{paper_category:{'parent_cat':best_parent,'category':paper_category,\n",
    "                                            'papers':[parsed_paper],'paper_count':1}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "for yr in data_model.keys():\n",
    "    for disc in data_model[yr].keys():\n",
    "        sorted_categories = ([k for (k,v) in sorted(data_model[yr][disc]['categories'].items(),\n",
    "                                                    key=lambda (k, v): v['parent_cat'],reverse=False)])\n",
    "        data_model[yr][disc]['children'] = ([{k:v for (k,v) in data_model[yr][disc]['categories'][category].iteritems()}\n",
    "                                              for category in sorted_categories])\n",
    "        data_model[yr][disc]['parents'] = list(set([k['parent_cat'] for k in data_model[yr][disc]['children']]))\n",
    "\n",
    "with open('C:/Users/Cole/Desktop/Udacity/Data Analyst Nano Degree/Project 6/Udacity-DSNDP6/disciplines.csv', 'w') as myfile:\n",
    "    disc_dict = {disc:disc for disc in data_model[max(data_model.keys())].keys()}\n",
    "    json.dump(disc_dict, myfile)\n",
    "    print 'success!'\n",
    "        \n",
    "with open('C:/Users/Cole/Desktop/Udacity/Data Analyst Nano Degree/Project 6/Udacity-DSNDP6/data_model.json', 'w') as fp:\n",
    "    json.dump(data_model, fp)\n",
    "    print 'success!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print [cat['paper_count'] for cat in data_model[2015]['cs']['children'] if cat['parent_cat']=='based design using']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'based design using', u'based mems using', u'analysis based using', u'design mems model', u'design fuzzy process', u'models uml using', u'based design mems', u'analysis design using', u'cs', u'generators micro power', u'based logic noise', u'array networks using', u'design optimization using', u'efficient fuzzy measures', u'data management model', u'asynchronous information systems', u'analysis comparative performance', u'control embedded systems', u'analysis methodology time', u'hard high low', u'asynchronous performance systems', u'design fabrication optimization', u'business computation systems', u'castor evolution vis', u'analysis data using', u'efficient generation management', u'analysis time using', u'application applications mobile', u'based detection using', u'based model using', u'neumann vis von', u'regular rewrite systems', u'knowledge management model', u'information systems technology', u'dynamic management power', u'algorithm based detection', u'modeling process surface', u'administration modeling theory', u'applications au solder', u'networks sensor wireless', u'embedded process systems', u'circuits digital using', u'computer robot science', u'asynchronous based systems', u'control integrating overview', u'based low power', u'computing distributed integrating', u'based networks wireless', u'applications mobile rf', u'architecture based logic', u'process rewrite systems', u'development robot surgery', u'development process technique', u'business pseudo systems', u'computation services systems', u'asynchronous systems time', u'applications computer modeling', u'fuzzy models uml', u'control digital systems', u'fuzzy multi scheduling', u'language numeration systems', u'algorithm detection integration', u'characterization modeling surface', u'asynchronous embedded systems', u'computer systems testing', u'efficient information measures', u'control embedded scheduling', u'control digital scheduling', u'fuzzy multi valued', u'based networks using', u'dynamic management model', u'conditions fuzzy intervals', u'control scheduling systems', u'computer problem science', u'control nstx overview', u'mems models simulation', u'business monitoring systems', u'detection fault logic', u'analysis centered perspective', u'based development web', u'design fabrication micro', u'business model process']\n"
     ]
    }
   ],
   "source": [
    "sorted_categories = ([k for (k,v) in sorted(data_model[2015]['cs']['categories'].items(), key=lambda (k, v): v['paper_count'],\n",
    "                                          reverse=True)])\n",
    "print sorted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    }
   ],
   "source": [
    "x = \"2015-10-21T09:36:09Z\"\n",
    "print int(x[0:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
